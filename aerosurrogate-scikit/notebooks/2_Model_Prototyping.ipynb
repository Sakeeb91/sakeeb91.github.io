{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aerodynamic Surrogate Model Prototyping\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the complete machine learning workflow for developing aerodynamic surrogate models using the Windsor body CFD dataset. We'll implement multiple regression algorithms, perform hyperparameter optimization, and evaluate models using both statistical and aerodynamic-specific metrics.\n",
    "\n",
    "## Objectives\n",
    "1. **Rapid Model Prototyping**: Quick evaluation of multiple algorithms\n",
    "2. **Hyperparameter Optimization**: Find optimal configurations for best models\n",
    "3. **Physics-Informed Validation**: Ensure models respect aerodynamic principles\n",
    "4. **Feature Importance Analysis**: Understand which parameters drive predictions\n",
    "5. **Model Comparison**: Comprehensive evaluation framework\n",
    "6. **Production Readiness**: Prepare models for deployment\n",
    "\n",
    "## Aerodynamic Context\n",
    "- **Primary Targets**: Drag coefficient (Cd) and Lift coefficient (Cl)\n",
    "- **Input Features**: 7 geometric parameters ‚Üí engineered to 25+ features ‚Üí optimally selected\n",
    "- **Physical Validation**: Ensure predictions follow fluid mechanics principles\n",
    "- **Performance Metrics**: R¬≤, RMSE, MAE, and aerodynamic-specific validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add src directory to path for imports\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Scientific computing\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Regression algorithms\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Project imports\n",
    "from data_processing import (\n",
    "    WindsorDataLoader, AerodynamicPreprocessor,\n",
    "    create_drag_preprocessor, create_lift_preprocessor,\n",
    "    create_multi_target_preprocessor\n",
    ")\n",
    "from train import AerodynamicModelTrainer\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "Load the Windsor body dataset and apply our advanced preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Windsor body dataset\n",
    "print(\"Loading Windsor body dataset...\")\n",
    "loader = WindsorDataLoader()\n",
    "features, targets = loader.get_feature_target_split()\n",
    "\n",
    "print(f\"Dataset loaded:\")\n",
    "print(f\"  Features shape: {features.shape}\")\n",
    "print(f\"  Targets shape: {targets.shape}\")\n",
    "print(f\"  Feature columns: {features.columns.tolist()}\")\n",
    "print(f\"  Target columns: {targets.columns.tolist()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of features:\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply advanced preprocessing for drag coefficient prediction\n",
    "print(\"Applying advanced preprocessing for drag coefficient prediction...\")\n",
    "\n",
    "# Create drag-specific preprocessor\n",
    "drag_preprocessor = create_drag_preprocessor(\n",
    "    n_features=12,\n",
    "    feature_selection_method='combined',\n",
    "    scaling_strategy='mixed'\n",
    ")\n",
    "\n",
    "# Prepare drag target\n",
    "y_drag = targets[['cd']]\n",
    "\n",
    "# Fit and transform\n",
    "X_processed_drag, y_processed_drag = drag_preprocessor.fit_transform(features, y_drag)\n",
    "\n",
    "print(f\"\\nDrag preprocessing results:\")\n",
    "print(f\"  Original features: {features.shape[1]}\")\n",
    "print(f\"  Processed features: {X_processed_drag.shape[1]}\")\n",
    "print(f\"  Selected features: {X_processed_drag.columns.tolist() if hasattr(X_processed_drag, 'columns') else 'Array format'}\")\n",
    "\n",
    "# Display preprocessing report\n",
    "print(\"\\nPreprocessing Pipeline Report:\")\n",
    "print(drag_preprocessor.generate_preprocessing_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train-test split for drag prediction\n",
    "X_train_drag, X_test_drag, y_train_drag, y_test_drag = drag_preprocessor.train_test_split(\n",
    "    X_processed_drag, y_processed_drag\n",
    ")\n",
    "\n",
    "print(f\"Train-test split for drag prediction:\")\n",
    "print(f\"  Training set: {X_train_drag.shape}\")\n",
    "print(f\"  Test set: {X_test_drag.shape}\")\n",
    "print(f\"  Target statistics:\")\n",
    "print(f\"    Train mean: {y_train_drag.mean().values[0]:.4f}\")\n",
    "print(f\"    Train std: {y_train_drag.std().values[0]:.4f}\")\n",
    "print(f\"    Test mean: {y_test_drag.mean().values[0]:.4f}\")\n",
    "print(f\"    Test std: {y_test_drag.std().values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rapid Model Prototyping\n",
    "\n",
    "Quickly evaluate multiple algorithms to identify the most promising approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a set of algorithms for rapid prototyping\n",
    "def rapid_model_evaluation(X_train, X_test, y_train, y_test, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Quickly evaluate multiple algorithms with default parameters.\n",
    "    \"\"\"\n",
    "    # Convert to appropriate format\n",
    "    y_train_flat = y_train.ravel() if y_train.ndim > 1 else y_train\n",
    "    y_test_flat = y_test.ravel() if y_test.ndim > 1 else y_test\n",
    "    \n",
    "    # Define models for rapid evaluation\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge': Ridge(alpha=1.0),\n",
    "        'Lasso': Lasso(alpha=0.1),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "        'SVR (RBF)': SVR(kernel='rbf', C=1.0),\n",
    "        'MLP': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Evaluating {name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Cross-validation\n",
    "            cv_scores = cross_val_score(model, X_train, y_train_flat, \n",
    "                                      cv=cv_folds, scoring='neg_mean_squared_error')\n",
    "            cv_rmse = np.sqrt(-cv_scores)\n",
    "            \n",
    "            # Fit and predict\n",
    "            model.fit(X_train, y_train_flat)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            r2 = r2_score(y_test_flat, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test_flat, y_pred))\n",
    "            mae = mean_absolute_error(y_test_flat, y_pred)\n",
    "            \n",
    "            results.append({\n",
    "                'Model': name,\n",
    "                'CV_RMSE_Mean': cv_rmse.mean(),\n",
    "                'CV_RMSE_Std': cv_rmse.std(),\n",
    "                'Test_R2': r2,\n",
    "                'Test_RMSE': rmse,\n",
    "                'Test_MAE': mae,\n",
    "                'Model_Object': model\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error with {name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('Test_R2', ascending=False)\n",
    "\n",
    "# Run rapid evaluation\n",
    "print(\"Starting rapid model evaluation for drag prediction...\")\n",
    "rapid_results = rapid_model_evaluation(X_train_drag, X_test_drag, y_train_drag, y_test_drag)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RAPID MODEL EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(rapid_results[['Model', 'Test_R2', 'Test_RMSE', 'CV_RMSE_Mean']].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize rapid evaluation results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# R¬≤ comparison\n",
    "ax1 = axes[0]\n",
    "models = rapid_results['Model'].values\n",
    "r2_scores = rapid_results['Test_R2'].values\n",
    "bars1 = ax1.bar(models, r2_scores, color='skyblue', alpha=0.8)\n",
    "ax1.set_ylabel('R¬≤ Score')\n",
    "ax1.set_title('Model Comparison - R¬≤ Score')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar, score in zip(bars1, r2_scores):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# RMSE comparison\n",
    "ax2 = axes[1]\n",
    "rmse_scores = rapid_results['Test_RMSE'].values\n",
    "bars2 = ax2.bar(models, rmse_scores, color='lightcoral', alpha=0.8)\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.set_title('Model Comparison - RMSE')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar, score in zip(bars2, rmse_scores):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "             f'{score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Rapid Model Evaluation - Drag Coefficient Prediction', y=1.02, fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Identify top 3 models\n",
    "top_models = rapid_results.head(3)\n",
    "print(f\"\\nTop 3 performing models:\")\n",
    "for i, (_, row) in enumerate(top_models.iterrows(), 1):\n",
    "    print(f\"  {i}. {row['Model']:15s}: R¬≤ = {row['Test_R2']:.4f}, RMSE = {row['Test_RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Optimization\n",
    "\n",
    "Optimize hyperparameters for the top-performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization for Random Forest (typically a top performer)\n",
    "print(\"Optimizing Random Forest hyperparameters...\")\n",
    "\n",
    "# Define parameter grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Random search for efficiency\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_search = RandomizedSearchCV(\n",
    "    rf_model, rf_param_grid, n_iter=30, cv=5, \n",
    "    scoring='neg_mean_squared_error', n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "# Fit and get results\n",
    "y_train_flat = y_train_drag.ravel()\n",
    "rf_search.fit(X_train_drag, y_train_flat)\n",
    "\n",
    "print(f\"Best Random Forest parameters:\")\n",
    "for param, value in rf_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest CV score (RMSE): {np.sqrt(-rf_search.best_score_):.4f}\")\n",
    "\n",
    "# Evaluate optimized model\n",
    "best_rf = rf_search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test_drag)\n",
    "y_test_flat = y_test_drag.ravel()\n",
    "\n",
    "rf_r2 = r2_score(y_test_flat, y_pred_rf)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test_flat, y_pred_rf))\n",
    "\n",
    "print(f\"Optimized Random Forest performance:\")\n",
    "print(f\"  Test R¬≤: {rf_r2:.4f}\")\n",
    "print(f\"  Test RMSE: {rf_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization for Gradient Boosting\n",
    "print(\"Optimizing Gradient Boosting hyperparameters...\")\n",
    "\n",
    "# Define parameter grid\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Random search\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_search = RandomizedSearchCV(\n",
    "    gb_model, gb_param_grid, n_iter=25, cv=5,\n",
    "    scoring='neg_mean_squared_error', n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "gb_search.fit(X_train_drag, y_train_flat)\n",
    "\n",
    "print(f\"Best Gradient Boosting parameters:\")\n",
    "for param, value in gb_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest CV score (RMSE): {np.sqrt(-gb_search.best_score_):.4f}\")\n",
    "\n",
    "# Evaluate optimized model\n",
    "best_gb = gb_search.best_estimator_\n",
    "y_pred_gb = best_gb.predict(X_test_drag)\n",
    "\n",
    "gb_r2 = r2_score(y_test_flat, y_pred_gb)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test_flat, y_pred_gb))\n",
    "\n",
    "print(f\"Optimized Gradient Boosting performance:\")\n",
    "print(f\"  Test R¬≤: {gb_r2:.4f}\")\n",
    "print(f\"  Test RMSE: {gb_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare optimized models\n",
    "optimized_results = pd.DataFrame([\n",
    "    {'Model': 'Random Forest (Optimized)', 'R2': rf_r2, 'RMSE': rf_rmse},\n",
    "    {'Model': 'Gradient Boosting (Optimized)', 'R2': gb_r2, 'RMSE': gb_rmse}\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OPTIMIZED MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(optimized_results.round(4))\n",
    "\n",
    "# Determine best model\n",
    "best_model_idx = optimized_results['R2'].idxmax()\n",
    "best_model_name = optimized_results.loc[best_model_idx, 'Model']\n",
    "best_model = best_rf if 'Random Forest' in best_model_name else best_gb\n",
    "best_predictions = y_pred_rf if 'Random Forest' in best_model_name else y_pred_gb\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model_name}\")\n",
    "print(f\"Best R¬≤: {optimized_results.loc[best_model_idx, 'R2']:.4f}\")\n",
    "print(f\"Best RMSE: {optimized_results.loc[best_model_idx, 'RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation and Visualization\n",
    "\n",
    "Comprehensive evaluation including prediction plots and residual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive evaluation plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Prediction vs Actual\n",
    "ax1 = axes[0, 0]\n",
    "ax1.scatter(y_test_flat, best_predictions, alpha=0.6, s=50)\n",
    "ax1.plot([y_test_flat.min(), y_test_flat.max()], [y_test_flat.min(), y_test_flat.max()], 'r--', lw=2)\n",
    "ax1.set_xlabel('True Drag Coefficient (Cd)')\n",
    "ax1.set_ylabel('Predicted Drag Coefficient (Cd)')\n",
    "ax1.set_title(f'{best_model_name}\\nPrediction vs Actual\\nR¬≤ = {optimized_results.loc[best_model_idx, \"R2\"]:.4f}')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add confidence bounds\n",
    "perfect_line = np.linspace(y_test_flat.min(), y_test_flat.max(), 100)\n",
    "error_margin = 0.05  # 5% error margin\n",
    "ax1.fill_between(perfect_line, perfect_line*(1-error_margin), perfect_line*(1+error_margin), \n",
    "                alpha=0.2, color='gray', label='¬±5% Error Band')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Residuals\n",
    "ax2 = axes[0, 1]\n",
    "residuals = best_predictions - y_test_flat\n",
    "ax2.scatter(best_predictions, residuals, alpha=0.6, s=50)\n",
    "ax2.axhline(y=0, color='r', linestyle='--')\n",
    "ax2.set_xlabel('Predicted Drag Coefficient (Cd)')\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.set_title('Residual Analysis')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistical info\n",
    "mean_residual = np.mean(residuals)\n",
    "std_residual = np.std(residuals)\n",
    "ax2.text(0.05, 0.95, f'Mean: {mean_residual:.4f}\\nStd: {std_residual:.4f}', \n",
    "         transform=ax2.transAxes, verticalalignment='top', \n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Plot 3: Error Distribution\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(residuals, bins=20, alpha=0.7, density=True, edgecolor='black')\n",
    "ax3.axvline(0, color='r', linestyle='--', label='Zero Error')\n",
    "ax3.set_xlabel('Residuals')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.set_title('Residual Distribution')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Overlay normal distribution\n",
    "x_norm = np.linspace(residuals.min(), residuals.max(), 100)\n",
    "normal_dist = stats.norm.pdf(x_norm, mean_residual, std_residual)\n",
    "ax3.plot(x_norm, normal_dist, 'r-', linewidth=2, label='Normal Fit')\n",
    "ax3.legend()\n",
    "\n",
    "# Plot 4: Learning Curve (if tree-based model)\n",
    "ax4 = axes[1, 1]\n",
    "if hasattr(best_model, 'estimators_'):\n",
    "    # For ensemble methods, show feature importance\n",
    "    feature_names = X_train_drag.columns if hasattr(X_train_drag, 'columns') else [f'Feature_{i}' for i in range(X_train_drag.shape[1])]\n",
    "    importance = best_model.feature_importances_\n",
    "    \n",
    "    # Sort by importance\n",
    "    sorted_idx = np.argsort(importance)[-10:]  # Top 10\n",
    "    \n",
    "    ax4.barh(range(len(sorted_idx)), importance[sorted_idx])\n",
    "    ax4.set_yticks(range(len(sorted_idx)))\n",
    "    ax4.set_yticklabels([feature_names[i] for i in sorted_idx])\n",
    "    ax4.set_xlabel('Feature Importance')\n",
    "    ax4.set_title('Top 10 Feature Importance')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "else:\n",
    "    # For other models, show Q-Q plot\n",
    "    from scipy.stats import probplot\n",
    "    probplot(residuals, dist=\"norm\", plot=ax4)\n",
    "    ax4.set_title('Q-Q Plot (Normality Test)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Comprehensive Model Evaluation - Drag Coefficient Prediction', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Physics-Informed Validation\n",
    "\n",
    "Validate that model predictions follow aerodynamic principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physics validation for drag predictions\n",
    "def validate_aerodynamic_physics(model, X_test, feature_names):\n",
    "    \"\"\"\n",
    "    Validate model predictions against known aerodynamic principles.\n",
    "    \"\"\"\n",
    "    print(\"Validating aerodynamic physics...\")\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Convert to DataFrame for easier manipulation\n",
    "    if hasattr(X_test, 'columns'):\n",
    "        X_df = X_test\n",
    "    else:\n",
    "        X_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "    \n",
    "    validation_results = {}\n",
    "    \n",
    "    # Test 1: Frontal area vs drag (should be positive correlation)\n",
    "    if 'frontal_area' in X_df.columns:\n",
    "        frontal_area_corr = np.corrcoef(X_df['frontal_area'], predictions)[0, 1]\n",
    "        validation_results['frontal_area_drag'] = {\n",
    "            'correlation': frontal_area_corr,\n",
    "            'expected': 'positive',\n",
    "            'is_correct': frontal_area_corr > 0,\n",
    "            'interpretation': 'Larger frontal area should increase drag due to higher blockage ratio'\n",
    "        }\n",
    "    \n",
    "    # Test 2: Clearance effects (complex relationship)\n",
    "    if 'clearance' in X_df.columns:\n",
    "        clearance_corr = np.corrcoef(X_df['clearance'], predictions)[0, 1]\n",
    "        validation_results['clearance_drag'] = {\n",
    "            'correlation': clearance_corr,\n",
    "            'expected': 'complex (can be positive or negative)',\n",
    "            'is_reasonable': abs(clearance_corr) < 0.8,  # Should not be extremely strong\n",
    "            'interpretation': 'Clearance affects underbody flow and ground effect'\n",
    "        }\n",
    "    \n",
    "    # Test 3: Physical bounds check\n",
    "    drag_min, drag_max = predictions.min(), predictions.max()\n",
    "    expected_min, expected_max = 0.1, 1.0  # Reasonable automotive drag range\n",
    "    \n",
    "    validation_results['physical_bounds'] = {\n",
    "        'min_predicted': drag_min,\n",
    "        'max_predicted': drag_max,\n",
    "        'expected_range': (expected_min, expected_max),\n",
    "        'within_bounds': (drag_min >= expected_min * 0.8) and (drag_max <= expected_max * 1.2),\n",
    "        'interpretation': 'Drag coefficients should be within reasonable automotive range'\n",
    "    }\n",
    "    \n",
    "    # Test 4: Prediction variance (should not be too extreme)\n",
    "    pred_std = np.std(predictions)\n",
    "    pred_mean = np.mean(predictions)\n",
    "    coeff_variation = pred_std / pred_mean\n",
    "    \n",
    "    validation_results['prediction_variance'] = {\n",
    "        'coefficient_of_variation': coeff_variation,\n",
    "        'is_reasonable': coeff_variation < 0.5,  # Should not vary more than 50%\n",
    "        'interpretation': 'Predictions should show reasonable variance across design space'\n",
    "    }\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "# Run physics validation\n",
    "feature_names = X_train_drag.columns if hasattr(X_train_drag, 'columns') else [f'feature_{i}' for i in range(X_train_drag.shape[1])]\n",
    "physics_results = validate_aerodynamic_physics(best_model, X_test_drag, feature_names)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHYSICS VALIDATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for test_name, results in physics_results.items():\n",
    "    print(f\"\\n{test_name.upper().replace('_', ' ')}:\")\n",
    "    for key, value in results.items():\n",
    "        if key == 'interpretation':\n",
    "            print(f\"  üí° {value}\")\n",
    "        elif key in ['is_correct', 'is_reasonable', 'within_bounds']:\n",
    "            status = \"‚úÖ PASS\" if value else \"‚ö†Ô∏è WARNING\"\n",
    "            print(f\"  {status}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-Target Model Training\n",
    "\n",
    "Train models to predict both drag and lift coefficients simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-target preprocessing for both drag and lift\n",
    "print(\"Preparing multi-target model for drag and lift prediction...\")\n",
    "\n",
    "# Create multi-target preprocessor\n",
    "multi_preprocessor = create_multi_target_preprocessor(\n",
    "    n_features=15,\n",
    "    feature_selection_method='combined',\n",
    "    scaling_strategy='mixed'\n",
    ")\n",
    "\n",
    "# Use both drag and lift targets\n",
    "y_multi = targets[['cd', 'cl']]\n",
    "\n",
    "# Fit and transform\n",
    "X_processed_multi, y_processed_multi = multi_preprocessor.fit_transform(features, y_multi)\n",
    "\n",
    "# Create train-test split\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = multi_preprocessor.train_test_split(\n",
    "    X_processed_multi, y_processed_multi\n",
    ")\n",
    "\n",
    "print(f\"Multi-target dataset:\")\n",
    "print(f\"  Training features: {X_train_multi.shape}\")\n",
    "print(f\"  Training targets: {y_train_multi.shape}\")\n",
    "print(f\"  Selected features: {X_processed_multi.shape[1]}\")\n",
    "print(f\"  Target columns: {y_multi.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multi-target models\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "print(\"Training multi-target models...\")\n",
    "\n",
    "# Define multi-target models\n",
    "multi_models = {\n",
    "    'Multi-RF': MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    'Multi-GB': MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, random_state=42)),\n",
    "    'Multi-SVR': MultiOutputRegressor(SVR(kernel='rbf'))\n",
    "}\n",
    "\n",
    "multi_results = []\n",
    "\n",
    "for name, model in multi_models.items():\n",
    "    print(f\"  Training {name}...\")\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train_multi, y_train_multi)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_multi = model.predict(X_test_multi)\n",
    "    \n",
    "    # Calculate metrics for each target\n",
    "    cd_r2 = r2_score(y_test_multi.iloc[:, 0], y_pred_multi[:, 0])\n",
    "    cd_rmse = np.sqrt(mean_squared_error(y_test_multi.iloc[:, 0], y_pred_multi[:, 0]))\n",
    "    \n",
    "    cl_r2 = r2_score(y_test_multi.iloc[:, 1], y_pred_multi[:, 1])\n",
    "    cl_rmse = np.sqrt(mean_squared_error(y_test_multi.iloc[:, 1], y_pred_multi[:, 1]))\n",
    "    \n",
    "    # Overall metrics\n",
    "    overall_r2 = (cd_r2 + cl_r2) / 2\n",
    "    overall_rmse = (cd_rmse + cl_rmse) / 2\n",
    "    \n",
    "    multi_results.append({\n",
    "        'Model': name,\n",
    "        'Cd_R2': cd_r2,\n",
    "        'Cd_RMSE': cd_rmse,\n",
    "        'Cl_R2': cl_r2,\n",
    "        'Cl_RMSE': cl_rmse,\n",
    "        'Overall_R2': overall_r2,\n",
    "        'Overall_RMSE': overall_rmse,\n",
    "        'Model_Object': model,\n",
    "        'Predictions': y_pred_multi\n",
    "    })\n",
    "\n",
    "multi_df = pd.DataFrame(multi_results).sort_values('Overall_R2', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MULTI-TARGET MODEL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(multi_df[['Model', 'Cd_R2', 'Cd_RMSE', 'Cl_R2', 'Cl_RMSE', 'Overall_R2']].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multi-target results\n",
    "best_multi_model = multi_df.iloc[0]['Model_Object']\n",
    "best_multi_pred = multi_df.iloc[0]['Predictions']\n",
    "best_multi_name = multi_df.iloc[0]['Model']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Drag coefficient predictions\n",
    "ax1 = axes[0, 0]\n",
    "cd_true = y_test_multi.iloc[:, 0]\n",
    "cd_pred = best_multi_pred[:, 0]\n",
    "ax1.scatter(cd_true, cd_pred, alpha=0.6, s=50, color='blue')\n",
    "ax1.plot([cd_true.min(), cd_true.max()], [cd_true.min(), cd_true.max()], 'r--', lw=2)\n",
    "ax1.set_xlabel('True Drag Coefficient (Cd)')\n",
    "ax1.set_ylabel('Predicted Drag Coefficient (Cd)')\n",
    "ax1.set_title(f'{best_multi_name} - Drag Prediction\\nR¬≤ = {multi_df.iloc[0][\"Cd_R2\"]:.4f}')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Lift coefficient predictions\n",
    "ax2 = axes[0, 1]\n",
    "cl_true = y_test_multi.iloc[:, 1]\n",
    "cl_pred = best_multi_pred[:, 1]\n",
    "ax2.scatter(cl_true, cl_pred, alpha=0.6, s=50, color='green')\n",
    "ax2.plot([cl_true.min(), cl_true.max()], [cl_true.min(), cl_true.max()], 'r--', lw=2)\n",
    "ax2.set_xlabel('True Lift Coefficient (Cl)')\n",
    "ax2.set_ylabel('Predicted Lift Coefficient (Cl)')\n",
    "ax2.set_title(f'{best_multi_name} - Lift Prediction\\nR¬≤ = {multi_df.iloc[0][\"Cl_R2\"]:.4f}')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals for drag\n",
    "ax3 = axes[1, 0]\n",
    "cd_residuals = cd_pred - cd_true\n",
    "ax3.scatter(cd_pred, cd_residuals, alpha=0.6, s=50, color='blue')\n",
    "ax3.axhline(y=0, color='r', linestyle='--')\n",
    "ax3.set_xlabel('Predicted Drag Coefficient (Cd)')\n",
    "ax3.set_ylabel('Residuals')\n",
    "ax3.set_title('Drag Coefficient Residuals')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals for lift\n",
    "ax4 = axes[1, 1]\n",
    "cl_residuals = cl_pred - cl_true\n",
    "ax4.scatter(cl_pred, cl_residuals, alpha=0.6, s=50, color='green')\n",
    "ax4.axhline(y=0, color='r', linestyle='--')\n",
    "ax4.set_xlabel('Predicted Lift Coefficient (Cl)')\n",
    "ax4.set_ylabel('Residuals')\n",
    "ax4.set_title('Lift Coefficient Residuals')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Multi-Target Model Evaluation - Drag and Lift Prediction', y=1.02, fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Performance summary\n",
    "print(f\"\\nBest multi-target model: {best_multi_name}\")\n",
    "print(f\"Drag coefficient R¬≤: {multi_df.iloc[0]['Cd_R2']:.4f}\")\n",
    "print(f\"Lift coefficient R¬≤: {multi_df.iloc[0]['Cl_R2']:.4f}\")\n",
    "print(f\"Overall R¬≤: {multi_df.iloc[0]['Overall_R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance and Interpretability\n",
    "\n",
    "Analyze which features are most important for aerodynamic predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "def analyze_feature_importance(model, feature_names, model_name):\n",
    "    \"\"\"\n",
    "    Extract and analyze feature importance from trained models.\n",
    "    \"\"\"\n",
    "    importance_data = []\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Tree-based models\n",
    "        importance = model.feature_importances_\n",
    "        importance_data = list(zip(feature_names, importance))\n",
    "        \n",
    "    elif hasattr(model, 'estimators_') and hasattr(model.estimators_[0], 'feature_importances_'):\n",
    "        # MultiOutput with tree-based estimators\n",
    "        # Average importance across all estimators\n",
    "        all_importance = np.array([est.feature_importances_ for est in model.estimators_])\n",
    "        avg_importance = np.mean(all_importance, axis=0)\n",
    "        importance_data = list(zip(feature_names, avg_importance))\n",
    "        \n",
    "    elif hasattr(model, 'coef_'):\n",
    "        # Linear models\n",
    "        coef = model.coef_\n",
    "        if coef.ndim > 1:\n",
    "            # Multi-output: average absolute coefficients\n",
    "            importance = np.mean(np.abs(coef), axis=0)\n",
    "        else:\n",
    "            importance = np.abs(coef)\n",
    "        importance_data = list(zip(feature_names, importance))\n",
    "    \n",
    "    if importance_data:\n",
    "        # Sort by importance\n",
    "        importance_data.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        importance_df = pd.DataFrame(importance_data, columns=['Feature', 'Importance'])\n",
    "        importance_df['Normalized_Importance'] = importance_df['Importance'] / importance_df['Importance'].sum()\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Analyze feature importance for best single-target model\n",
    "feature_names_drag = X_train_drag.columns if hasattr(X_train_drag, 'columns') else [f'feature_{i}' for i in range(X_train_drag.shape[1])]\n",
    "importance_drag = analyze_feature_importance(best_model, feature_names_drag, best_model_name)\n",
    "\n",
    "if importance_drag is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"FEATURE IMPORTANCE - {best_model_name.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    print(importance_drag.head(10).round(4))\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Top 10 features\n",
    "    top_features = importance_drag.head(10)\n",
    "    \n",
    "    plt.barh(range(len(top_features)), top_features['Importance'], color='skyblue')\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 10 Feature Importance - {best_model_name}\\nDrag Coefficient Prediction')\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (feature, importance) in enumerate(zip(top_features['Feature'], top_features['Importance'])):\n",
    "        plt.text(importance + 0.001, i, f'{importance:.3f}', va='center', fontsize=9)\n",
    "    \n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Feature importance not available for {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance for multi-target model\n",
    "feature_names_multi = X_train_multi.columns if hasattr(X_train_multi, 'columns') else [f'feature_{i}' for i in range(X_train_multi.shape[1])]\n",
    "importance_multi = analyze_feature_importance(best_multi_model, feature_names_multi, best_multi_name)\n",
    "\n",
    "if importance_multi is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"FEATURE IMPORTANCE - {best_multi_name.upper()} (MULTI-TARGET)\")\n",
    "    print(\"=\"*60)\n",
    "    print(importance_multi.head(10).round(4))\n",
    "    \n",
    "    # Compare feature importance between models\n",
    "    if importance_drag is not None:\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Get common features\n",
    "        common_features = set(importance_drag['Feature']).intersection(set(importance_multi['Feature']))\n",
    "        \n",
    "        if common_features:\n",
    "            # Create comparison DataFrame\n",
    "            comparison_data = []\n",
    "            for feature in common_features:\n",
    "                drag_imp = importance_drag[importance_drag['Feature'] == feature]['Normalized_Importance'].values[0]\n",
    "                multi_imp = importance_multi[importance_multi['Feature'] == feature]['Normalized_Importance'].values[0]\n",
    "                comparison_data.append({\n",
    "                    'Feature': feature,\n",
    "                    'Drag_Model': drag_imp,\n",
    "                    'Multi_Model': multi_imp\n",
    "                })\n",
    "            \n",
    "            comparison_df = pd.DataFrame(comparison_data)\n",
    "            comparison_df['Avg_Importance'] = (comparison_df['Drag_Model'] + comparison_df['Multi_Model']) / 2\n",
    "            comparison_df = comparison_df.sort_values('Avg_Importance', ascending=False).head(10)\n",
    "            \n",
    "            # Create comparison plot\n",
    "            x = np.arange(len(comparison_df))\n",
    "            width = 0.35\n",
    "            \n",
    "            plt.bar(x - width/2, comparison_df['Drag_Model'], width, label='Drag-Only Model', alpha=0.8)\n",
    "            plt.bar(x + width/2, comparison_df['Multi_Model'], width, label='Multi-Target Model', alpha=0.8)\n",
    "            \n",
    "            plt.xlabel('Features')\n",
    "            plt.ylabel('Normalized Feature Importance')\n",
    "            plt.title('Feature Importance Comparison\\nDrag-Only vs Multi-Target Models')\n",
    "            plt.xticks(x, comparison_df['Feature'], rotation=45, ha='right')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3, axis='y')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"\\nFeature Importance Comparison (Top 10):\")\n",
    "            print(comparison_df[['Feature', 'Drag_Model', 'Multi_Model']].round(4))\n",
    "        else:\n",
    "            print(\"No common features found between models for comparison.\")\n",
    "else:\n",
    "    print(f\"Feature importance not available for {best_multi_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Persistence and Production Readiness\n",
    "\n",
    "Save the best models and create a simple prediction interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best models and preprocessors\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save drag model and preprocessor\n",
    "drag_model_path = models_dir / f'best_drag_model_{timestamp}.pkl'\n",
    "drag_preprocessor_path = models_dir / f'drag_preprocessor_{timestamp}.pkl'\n",
    "\n",
    "with open(drag_model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open(drag_preprocessor_path, 'wb') as f:\n",
    "    pickle.dump(drag_preprocessor, f)\n",
    "\n",
    "print(f\"Drag model saved to: {drag_model_path}\")\n",
    "print(f\"Drag preprocessor saved to: {drag_preprocessor_path}\")\n",
    "\n",
    "# Save multi-target model and preprocessor\n",
    "multi_model_path = models_dir / f'best_multi_model_{timestamp}.pkl'\n",
    "multi_preprocessor_path = models_dir / f'multi_preprocessor_{timestamp}.pkl'\n",
    "\n",
    "with open(multi_model_path, 'wb') as f:\n",
    "    pickle.dump(best_multi_model, f)\n",
    "\n",
    "with open(multi_preprocessor_path, 'wb') as f:\n",
    "    pickle.dump(multi_preprocessor, f)\n",
    "\n",
    "print(f\"Multi-target model saved to: {multi_model_path}\")\n",
    "print(f\"Multi-target preprocessor saved to: {multi_preprocessor_path}\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'timestamp': timestamp,\n",
    "    'best_drag_model': {\n",
    "        'name': best_model_name,\n",
    "        'r2_score': optimized_results.loc[best_model_idx, 'R2'],\n",
    "        'rmse': optimized_results.loc[best_model_idx, 'RMSE'],\n",
    "        'model_path': str(drag_model_path),\n",
    "        'preprocessor_path': str(drag_preprocessor_path)\n",
    "    },\n",
    "    'best_multi_model': {\n",
    "        'name': best_multi_name,\n",
    "        'cd_r2': multi_df.iloc[0]['Cd_R2'],\n",
    "        'cl_r2': multi_df.iloc[0]['Cl_R2'],\n",
    "        'overall_r2': multi_df.iloc[0]['Overall_R2'],\n",
    "        'model_path': str(multi_model_path),\n",
    "        'preprocessor_path': str(multi_preprocessor_path)\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'original_features': features.shape[1],\n",
    "        'processed_features_drag': X_processed_drag.shape[1],\n",
    "        'processed_features_multi': X_processed_multi.shape[1],\n",
    "        'samples': features.shape[0]\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = models_dir / f'model_metadata_{timestamp}.json'\n",
    "import json\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Model metadata saved to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple prediction interface\n",
    "def create_prediction_interface():\n",
    "    \"\"\"\n",
    "    Create a simple interface for making predictions with trained models.\n",
    "    \"\"\"\n",
    "    class AerodynamicPredictor:\n",
    "        def __init__(self, drag_model, drag_preprocessor, multi_model, multi_preprocessor):\n",
    "            self.drag_model = drag_model\n",
    "            self.drag_preprocessor = drag_preprocessor\n",
    "            self.multi_model = multi_model\n",
    "            self.multi_preprocessor = multi_preprocessor\n",
    "        \n",
    "        def predict_drag(self, geometric_params):\n",
    "            \"\"\"\n",
    "            Predict drag coefficient from geometric parameters.\n",
    "            \n",
    "            Args:\n",
    "                geometric_params: DataFrame or dict with geometric parameters\n",
    "            \n",
    "            Returns:\n",
    "                Predicted drag coefficient\n",
    "            \"\"\"\n",
    "            if isinstance(geometric_params, dict):\n",
    "                geometric_params = pd.DataFrame([geometric_params])\n",
    "            \n",
    "            # Preprocess\n",
    "            X_processed = self.drag_preprocessor.transform(geometric_params)\n",
    "            \n",
    "            # Predict\n",
    "            prediction = self.drag_model.predict(X_processed)\n",
    "            \n",
    "            return prediction[0] if len(prediction) == 1 else prediction\n",
    "        \n",
    "        def predict_multi(self, geometric_params):\n",
    "            \"\"\"\n",
    "            Predict both drag and lift coefficients from geometric parameters.\n",
    "            \n",
    "            Args:\n",
    "                geometric_params: DataFrame or dict with geometric parameters\n",
    "            \n",
    "            Returns:\n",
    "                Dictionary with 'cd' and 'cl' predictions\n",
    "            \"\"\"\n",
    "            if isinstance(geometric_params, dict):\n",
    "                geometric_params = pd.DataFrame([geometric_params])\n",
    "            \n",
    "            # Preprocess\n",
    "            X_processed = self.multi_preprocessor.transform(geometric_params)\n",
    "            \n",
    "            # Predict\n",
    "            predictions = self.multi_model.predict(X_processed)\n",
    "            \n",
    "            if predictions.ndim == 1:\n",
    "                return {'cd': predictions[0], 'cl': predictions[1]}\n",
    "            else:\n",
    "                return [{'cd': pred[0], 'cl': pred[1]} for pred in predictions]\n",
    "        \n",
    "        def validate_inputs(self, geometric_params):\n",
    "            \"\"\"\n",
    "            Validate input parameters are within reasonable ranges.\n",
    "            \"\"\"\n",
    "            required_params = [\n",
    "                'ratio_length_back_fast',\n",
    "                'ratio_height_nose_windshield', \n",
    "                'ratio_height_fast_back',\n",
    "                'side_taper',\n",
    "                'clearance',\n",
    "                'bottom_taper_angle',\n",
    "                'frontal_area'\n",
    "            ]\n",
    "            \n",
    "            if isinstance(geometric_params, dict):\n",
    "                missing = set(required_params) - set(geometric_params.keys())\n",
    "                if missing:\n",
    "                    return False, f\"Missing parameters: {missing}\"\n",
    "            \n",
    "            return True, \"Valid inputs\"\n",
    "    \n",
    "    return AerodynamicPredictor(best_model, drag_preprocessor, best_multi_model, multi_preprocessor)\n",
    "\n",
    "# Create predictor instance\n",
    "predictor = create_prediction_interface()\n",
    "\n",
    "print(\"Prediction interface created successfully!\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"predictor.predict_drag(geometric_parameters)\")\n",
    "print(\"predictor.predict_multi(geometric_parameters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the prediction interface with a test case\n",
    "print(\"Testing prediction interface with sample geometric parameters...\")\n",
    "\n",
    "# Create a test case with reasonable geometric parameters\n",
    "test_geometry = {\n",
    "    'ratio_length_back_fast': 0.5,\n",
    "    'ratio_height_nose_windshield': 0.3,\n",
    "    'ratio_height_fast_back': 0.2,\n",
    "    'side_taper': 15.0,\n",
    "    'clearance': 100.0,\n",
    "    'bottom_taper_angle': 10.0,\n",
    "    'frontal_area': 0.08\n",
    "}\n",
    "\n",
    "# Validate inputs\n",
    "is_valid, message = predictor.validate_inputs(test_geometry)\n",
    "print(f\"Input validation: {message}\")\n",
    "\n",
    "if is_valid:\n",
    "    # Test drag prediction\n",
    "    drag_pred = predictor.predict_drag(test_geometry)\n",
    "    print(f\"\\nDrag coefficient prediction: {drag_pred:.4f}\")\n",
    "    \n",
    "    # Test multi-target prediction\n",
    "    multi_pred = predictor.predict_multi(test_geometry)\n",
    "    print(f\"Multi-target predictions:\")\n",
    "    print(f\"  Drag coefficient (Cd): {multi_pred['cd']:.4f}\")\n",
    "    print(f\"  Lift coefficient (Cl): {multi_pred['cl']:.4f}\")\n",
    "    \n",
    "    # Physical interpretation\n",
    "    print(f\"\\nPhysical interpretation:\")\n",
    "    if multi_pred['cd'] < 0.3:\n",
    "        print(f\"  üöó Low drag configuration - excellent for fuel efficiency\")\n",
    "    elif multi_pred['cd'] < 0.4:\n",
    "        print(f\"  üöô Moderate drag - typical automotive range\")\n",
    "    else:\n",
    "        print(f\"  üöõ High drag - may need aerodynamic optimization\")\n",
    "    \n",
    "    if multi_pred['cl'] < -0.1:\n",
    "        print(f\"  ‚¨áÔ∏è Generates downforce - improves high-speed stability\")\n",
    "    elif multi_pred['cl'] > 0.1:\n",
    "        print(f\"  ‚¨ÜÔ∏è Generates lift - may reduce traction at high speeds\")\n",
    "    else:\n",
    "        print(f\"  ‚û°Ô∏è Neutral lift - balanced aerodynamic behavior\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PROTOTYPING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ Successfully trained and validated aerodynamic surrogate models\")\n",
    "print(f\"‚úÖ Best drag model: {best_model_name} (R¬≤ = {optimized_results.loc[best_model_idx, 'R2']:.4f})\")\n",
    "print(f\"‚úÖ Best multi-target model: {best_multi_name} (Overall R¬≤ = {multi_df.iloc[0]['Overall_R2']:.4f})\")\n",
    "print(f\"‚úÖ Models validated against aerodynamic physics principles\")\n",
    "print(f\"‚úÖ Feature importance analysis completed\")\n",
    "print(f\"‚úÖ Models saved and ready for production deployment\")\n",
    "print(f\"‚úÖ Prediction interface created and tested\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}