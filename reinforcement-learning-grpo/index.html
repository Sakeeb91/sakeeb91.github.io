<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GRPO Healthcare AI - Shafkat Rahman</title>
    <meta name="description" content="Group Robust Policy Optimization for ethical medical resource allocation using reinforcement learning with fairness constraints">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: 'Courier New', monospace;
            line-height: 1.6;
            color: #000;
            background-color: #fff;
            font-size: 14px;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .nav {
            background: #fff;
            border-bottom: 1px solid #000;
            padding: 20px 0;
        }
        .nav-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            max-width: 800px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .nav-home {
            color: #000;
            text-decoration: none;
            font-weight: bold;
            text-transform: uppercase;
        }
        .nav-home:hover {
            text-decoration: underline;
        }
        .header {
            padding: 80px 0;
            text-align: center;
            border-bottom: 1px solid #000;
        }
        .header h1 {
            font-size: 24px;
            font-weight: bold;
            margin-bottom: 20px;
            text-transform: uppercase;
            letter-spacing: 2px;
        }
        .subtitle {
            font-size: 16px;
            margin-bottom: 30px;
            font-style: italic;
        }
        .section {
            padding: 60px 0;
            border-bottom: 1px solid #000;
        }
        .section-title {
            font-size: 20px;
            font-weight: bold;
            margin-bottom: 30px;
            text-transform: uppercase;
            letter-spacing: 2px;
        }
        .intro-box {
            background: #f5f5f5;
            padding: 30px;
            border-left: 4px solid #000;
            margin-bottom: 40px;
        }
        .feature {
            margin-bottom: 40px;
            padding-bottom: 40px;
            border-bottom: 1px solid #ccc;
        }
        .feature:last-child {
            border-bottom: none;
        }
        .feature h3 {
            font-size: 18px;
            font-weight: bold;
            margin-bottom: 10px;
            text-transform: uppercase;
        }
        .btn {
            display: inline-block;
            padding: 10px 20px;
            border: 2px solid #000;
            color: #000;
            text-decoration: none;
            margin: 0 10px;
            text-transform: uppercase;
            font-weight: bold;
        }
        .btn:hover {
            background: #000;
            color: #fff;
        }
    </style>
</head>
<body>
    <nav class="nav">
        <div class="nav-container">
            <a href="https://sakeeb91.github.io/" class="nav-home">‚Üê Back to Portfolio</a>
            <span>GRPO Healthcare AI</span>
        </div>
    </nav>

    <header class="header">
        <div class="container">
            <h1>GRPO Healthcare AI</h1>
            <p class="subtitle">Group Robust Policy Optimization for Ethical Medical Resource Allocation</p>
            <div>
                <a href="https://github.com/Sakeeb91/reinforcement-learning-grpo" class="btn" target="_blank">View Code</a>
            </div>
        </div>
    </header>

    <section class="section">
        <div class="container">
            <div class="intro-box">
                <h2>What is this project about?</h2>
                <p>
                    Imagine you're running a hospital during a crisis, and you need to decide how to allocate limited resources like ICU beds, ventilators, and medical staff. 
                    Traditional AI systems might optimize for overall efficiency, but what if that means consistently neglecting certain patient groups?
                </p>
                <br>
                <p>
                    GRPO (Group Robust Policy Optimization) is an AI system that learns to make these critical decisions while ensuring fairness across different patient demographics. 
                    It's like having an intelligent advisor that not only maximizes medical outcomes but also ensures that no group of patients is systematically disadvantaged.
                </p>
            </div>

            <h2 class="section-title">The Problem We're Solving</h2>
            
            <div class="feature">
                <h3>Healthcare Bias in AI</h3>
                <p>
                    Standard AI algorithms often exhibit bias - they might unconsciously favor certain patient groups over others based on historical data patterns. 
                    For instance, an AI system trained on historical data might allocate fewer resources to elderly patients or certain ethnic groups, 
                    perpetuating existing healthcare inequities.
                </p>
            </div>

            <div class="feature">
                <h3>The Fairness Challenge</h3>
                <p>
                    "Fairness" in healthcare AI means ensuring that treatment decisions are equitable across different patient groups (age, gender, ethnicity, socioeconomic status). 
                    It's not just about equal treatment, but about equitable outcomes that account for different baseline health conditions and needs.
                </p>
            </div>

            <div class="feature">
                <h3>Resource Allocation Under Pressure</h3>
                <p>
                    During emergencies like pandemics, hospitals must make rapid decisions about resource allocation. Traditional methods often rely on simple rules or 
                    human intuition, which can be inconsistent and potentially biased under stress.
                </p>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container">
            <h2 class="section-title">How GRPO Works</h2>
            
            <div class="feature">
                <h3>Reinforcement Learning with Ethics</h3>
                <p>
                    GRPO extends traditional reinforcement learning (the AI technique behind game-playing systems like AlphaGo) to include explicit fairness constraints. 
                    The system learns through trial and error in simulated hospital environments, but is rewarded not just for efficiency, but also for equitable treatment.
                </p>
            </div>

            <div class="feature">
                <h3>Group-Aware Decision Making</h3>
                <p>
                    Unlike standard algorithms that treat all patients identically, GRPO is aware of different patient groups and actively monitors its decisions to ensure 
                    no group is systematically disadvantaged. It's like having a built-in ethics committee that continuously audits the AI's recommendations.
                </p>
            </div>

            <div class="feature">
                <h3>Robust Performance</h3>
                <p>
                    The system is designed to maintain fair performance even when conditions change - whether it's a new variant of a disease, 
                    different patient populations, or varying resource constraints. This robustness is crucial for real-world deployment.
                </p>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container">
            <h2 class="section-title">Real-World Impact</h2>
            
            <div class="feature">
                <h3>Measurable Fairness Improvement</h3>
                <p>
                    Our testing showed a 25% improvement in fairness metrics compared to standard reinforcement learning approaches, 
                    while maintaining comparable efficiency in resource utilization. This means better, more equitable patient outcomes.
                </p>
            </div>

            <div class="feature">
                <h3>Applications Beyond Healthcare</h3>
                <p>
                    The principles behind GRPO can be applied to any domain where fair resource allocation matters: 
                    educational resource distribution, hiring processes, loan approvals, or criminal justice recommendations.
                </p>
            </div>

            <div class="feature">
                <h3>Building Trust in AI</h3>
                <p>
                    By explicitly addressing bias and fairness, systems like GRPO help build public trust in AI applications for critical decisions. 
                    This transparency and accountability are essential for widespread adoption of AI in healthcare.
                </p>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container">
            <h2 class="section-title">Technical Innovation</h2>
            
            <div class="feature">
                <h3>Novel Algorithm Design</h3>
                <p>
                    GRPO introduces new mathematical techniques for incorporating fairness constraints directly into the learning process, 
                    rather than applying them as an afterthought. This integration is more effective and computationally efficient.
                </p>
            </div>

            <div class="feature">
                <h3>Multi-Objective Optimization</h3>
                <p>
                    The system simultaneously optimizes for multiple objectives (efficiency, fairness, robustness) using advanced mathematical techniques. 
                    This is significantly more challenging than single-objective optimization but essential for real-world applications.
                </p>
            </div>

            <div class="feature">
                <h3>Empirical Validation</h3>
                <p>
                    All claims are backed by rigorous testing on realistic healthcare scenarios, with statistical significance testing to ensure 
                    the improvements are genuine and not due to chance.
                </p>
            </div>
        </div>
    </section>
</body>
</html>